{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae21a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading the wine dataset ...\n",
      "2.1. Balancing the data classes ...\n",
      "2.2. Shuffling the data then splitting them in 70% training and 30% test ...\n",
      "3.1. Choosing the DecisionTreeClassifier()'s algorithm to predict wine classes ...\n",
      "3.2. Training the DecisionTreeClassifier()'s algorithm ...\n",
      "4.1. The DecisionTreeClassifier()'s algorithm is making prediction ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.1. The \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms algorithm is making prediction ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_smote_test)\n\u001b[1;32m---> 52\u001b[0m accuracy_score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.1. The \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms algorithm accuracy score is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mf1_score(expected, predicted, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\sklearn_wine_dataset\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\sklearn_wine_dataset\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\sklearn_wine_dataset\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Laden der Daten\n",
    "# Laden Sie die Daten in den Arbeitsspeicher, um die Daten anschließend zu verarbeiten. \n",
    "print(\"1. Loading the wine dataset ...\")\n",
    "wine_bunch = load_wine()\n",
    "\n",
    "\n",
    "X = wine_bunch['data']\n",
    "y = wine_bunch['target']\n",
    "\n",
    "#2. Teilen der Daten in Training und Test\n",
    "# Bitte achten Sie auf eine zufällige Aufteilung der Daten und eine Ausgeglichenheit der Klassen, dabei sollen 70% der Daten zum Training verwendet werden.\n",
    "smote = SMOTE()\n",
    "print(\"2.1. Balancing the data classes ...\")\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"2.2. Shuffling the data then splitting them in 70% training and 30% test ...\")\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, shuffle=True, train_size=0.7, random_state=42)\n",
    "\n",
    "\n",
    "#3. Trainieren eines geeigneten Algorithmus\n",
    "# Wählen Sie einen geeigneten Algorithmus aus, um die Sorten des Weins vorherzusagen. Trainieren Sie den Algorithmus. \n",
    "print(f\"3.1. Choosing the {model}'s algorithm to predict wine classes ...\")\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "print(f\"3.2. Training the {model}'s algorithm ...\")\n",
    "model.fit(X_smote_train, y_smote_train)\n",
    "\n",
    "\n",
    "# 4. Testen des Algorithmus auf den Testdaten\n",
    "# Berechnen Sie mindestens ein Maß für die Genauigkeit der Vorhersage.\n",
    "expected = X_smote_test\n",
    "print(f\"4.1. The {model}'s algorithm is making prediction ...\")\n",
    "predicted = model.predict(X_smote_test)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(expected, predicted)\n",
    "print(f\"4.2.1. The {model}'s algorithm accuracy score is {accuracy_score}\")\n",
    "\n",
    "f1_score = metrics.f1_score(expected, predicted, average=None)\n",
    "print(f\"4.2.2. The {model}'s algorithm f1 score is {f1_score}\")\n",
    "\n",
    "# 5. Illustration\n",
    "# Stellen Sie graphisch dar, wie viele Weine der jeweiligen Klasse richtig vorhergesagt wurden.\n",
    "print(f\"5. Illustrating the {model}'s algorithm predictions ...\")\n",
    "correct_predictions = [0, 0, 0]\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == expected[i]:\n",
    "        correct_predictions[predicted[i]] += 1\n",
    "fig = plt.figure()\n",
    "fig.suptitle(model+\" correct predictions illstration\", fontsize=12)\n",
    "axes = fig.add_axes([0,0,1,1])\n",
    "classes = ['class 0', 'class 1', 'class 2']\n",
    "axes.bar(classes,correct_predictions)\n",
    "plt.savefig(Path('result') / file_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fe99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600446b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
